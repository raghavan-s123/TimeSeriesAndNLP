import pandas as pd
import os
import sys
import warnings

from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.multiclass import OneVsRestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score

warnings.simplefilter("ignore")

from nlp_utils import clean_text, split_labels, split_data

def main():

    filename = input("Enter dataset filename (CSV or Excel): ").strip()
    file_path = os.path.join(sys.path[0], filename)

    if filename.endswith(".csv"):
        df = pd.read_csv(file_path)
    elif filename.endswith((".xls", ".xlsx")):
        df = pd.read_excel(file_path, engine="openpyxl")
    else:
        print("Only CSV or Excel files supported")
        sys.exit(1)

    print("\n=== Dataset Preview ===")
    print(df.head())

    train, test = split_data(df)

    train["clean_text"] = train["text"].apply(clean_text)
    test["clean_text"] = test["text"].apply(clean_text)

    # ================= Binary =================
    print("\n===== Binary Classification =====")
    binary_pipeline = Pipeline([
        ("tfidf", TfidfVectorizer(max_features=2000)),
        ("clf", LogisticRegression(max_iter=1000))
    ])

    binary_pipeline.fit(train["clean_text"], train["binary_sentiment"])
    binary_preds = binary_pipeline.predict(test["clean_text"])
    print("Binary Predictions:", binary_preds[:10])

    # Binary Evaluation
    binary_true = test["binary_sentiment"]
    print("\nBinary Accuracy:", accuracy_score(binary_true, binary_preds))
    print("\nBinary Classification Report:\n", classification_report(binary_true, binary_preds))
    print("Binary Confusion Matrix:\n", confusion_matrix(binary_true, binary_preds))

    # ================= Multi-Class =================
    print("\n===== Multi-Class Classification =====")
    le = LabelEncoder()
    train["sentiment_encoded"] = le.fit_transform(train["sentiment"])
    test["sentiment_encoded"] = le.transform(test["sentiment"])

    multi_pipeline = Pipeline([
        ("tfidf", TfidfVectorizer(max_features=2000)),
        ("clf", MultinomialNB())
    ])

    multi_pipeline.fit(train["clean_text"], train["sentiment_encoded"])
    multi_preds = multi_pipeline.predict(test["clean_text"])
    print("Multi-Class Predictions:", multi_preds[:10])

    # Multi-Class Evaluation
    multi_true = test["sentiment_encoded"]
    print("\nMulti-Class Accuracy:", accuracy_score(multi_true, multi_preds))
    print("\nMulti-Class Classification Report:\n", classification_report(multi_true, multi_preds))
    print("Multi-Class Confusion Matrix:\n", confusion_matrix(multi_true, multi_preds))

    # ================= Multi-Label =================
    print("\n===== Multi-Label Classification =====")
    train["emotion_list"] = train["emotion_labels"].apply(split_labels)
    test["emotion_list"] = test["emotion_labels"].apply(split_labels)

    mlb = MultiLabelBinarizer()
    Y_train = mlb.fit_transform(train["emotion_list"])
    Y_test_mlabel = mlb.transform(test["emotion_list"])

    multilabel_pipeline = Pipeline([
        ("tfidf", TfidfVectorizer(max_features=2000)),
        ("clf", OneVsRestClassifier(LogisticRegression(max_iter=1000)))
    ])

    multilabel_pipeline.fit(train["clean_text"], Y_train)
    multi_label_preds = multilabel_pipeline.predict(test["clean_text"])
    print("Multi-Label Predictions (first 5 rows):\n", multi_label_preds[:5])
    print("Classes:", mlb.classes_)

    # Multi-Label Evaluation
    micro_f1 = f1_score(Y_test_mlabel, multi_label_preds, average="micro", zero_division=0)
    macro_f1 = f1_score(Y_test_mlabel, multi_label_preds, average="macro", zero_division=0)
    per_label_f1 = f1_score(Y_test_mlabel, multi_label_preds, average=None, zero_division=0)

    print("\nMulti-Label Micro F1 Score:", micro_f1)
    print("Multi-Label Macro F1 Score:", macro_f1)
    print("\nPer-Label F1 Scores:")
    for emotion, score in zip(mlb.classes_, per_label_f1):
        print(f"{emotion}: {score:.4f}")

    # ================= Cross-Model Summary =================
    print("\n========== SUMMARY ==========")
    print("Binary Accuracy:", accuracy_score(binary_true, binary_preds))
    print("Multi-Class Accuracy:", accuracy_score(multi_true, multi_preds))
    print("Multi-Label Micro F1:", micro_f1)
    print("Multi-Label Macro F1:", macro_f1)


if __name__ == "__main__":
    main()
